{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: solid blue 2px; padding: 20px; margin: 10px\">\n",
    "\n",
    "  <b>Overall Summary of the Project ‚Äì Iteration 1</b><br><br>\n",
    "  Hello Andy, Congratulations on submitting your project! üéâ<br><br>\n",
    "  My name is <b>Victor Camargo</b> \n",
    "  (<a href=\"https://hub.tripleten.com/u/834cb557\" target=\"_blank\">TripleTen Hub profile</a>) and I‚Äôll be reviewing your project today.<br><br>\n",
    "\n",
    "  <b>Nice work on:</b><br>\n",
    "  ‚úÖ Proper data loading and inspection with clean structure and no missing values.<br>\n",
    "  ‚úÖ Clear and correct 60/20/20 split ensuring reproducibility.<br>\n",
    "  ‚úÖ Excellent comparison of models, well-reasoned interpretation, and detailed final evaluation with precision, recall, and accuracy metrics.<br><br>\n",
    "\n",
    "  Your work is complete, consistent, and meets all project requirements. The explanations are clear, and you demonstrated a solid understanding of model selection, validation, and evaluation.<br><br>\n",
    "\n",
    "  üü¢ Project status: <b>Approved ‚Äì great work!</b><br><br>\n",
    "\n",
    "  <hr><b>Legend:</b><br>\n",
    "\n",
    "  <div class=\"alert alert-success\" style=\"border-left: 7px solid green; padding: 5px\">\n",
    "    <b>‚úÖ Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "    Efficient solutions, strong ideas, or formatting done well. These can often be reused in future projects.\n",
    "  </div>\n",
    "\n",
    "  <div class=\"alert alert-warning\" style=\"border-left: 7px solid gold; padding: 5px\">\n",
    "    <b>‚ö†Ô∏è Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "    Suggestions for optimisation. They are not mandatory but highly recommended to strengthen your work.\n",
    "  </div>\n",
    "\n",
    "  <div class=\"alert alert-danger\" style=\"border-left: 7px solid red; padding: 5px\">\n",
    "    <b>‚õîÔ∏è Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "    Indicates a problem that must be fixed. The project can‚Äôt be approved until this is resolved.\n",
    "  </div>\n",
    "\n",
    "  <div class=\"alert alert-info\" style=\"border-left: 7px solid blue; padding: 5px\">\n",
    "    <b>üîµ Student‚Äôs Comment</b><br>\n",
    "    To leave your own notes, questions, or explanations, create a <b>Markdown cell</b> in your notebook and copy-paste this code:<br>\n",
    "    <code>&lt;div class=\"alert alert-info\"; style=\"border-left: 7px solid blue\"&gt;&lt;b&gt;Student‚Äôs Comment&lt;/b&gt;&lt;/div&gt;</code>\n",
    "  </div>\n",
    "\n",
    "  <hr>\n",
    "  <b>Please ensure</b> that all cells run smoothly from top to bottom and display their outputs before submitting ‚Äî this helps keep your analysis easy to follow.<br>\n",
    "  <b>Kind reminder:</b> please do not remove or change reviewer comments, as they help track progress and make future reviews smoother.<br>\n",
    "  <b>Feel free to reach out if you need help in the Questions channel.</b>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Intro to Machine Learning: Project\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Project Description\n",
    "--------------------\n",
    "Mobile carrier Megaline has found out that many of their subscribers use legacy plans. They want to develop a model that would analyze subscribers' behavior and recommend one of Megaline's newer plans: Smart or Ultra. \n",
    "\n",
    "You have access to behavior data about subscribers who have already switched to the new plans (from the project for the Statistical Data Analysis course). For this classification task, you need to develop a model that will pick the right plan. Since you‚Äôve already performed the data preprocessing step, you can move straight to creating the model.  \n",
    "\n",
    "Develop a model with the highest possible accuracy. In this project, the threshold for accuracy is 0.75. Check the accuracy using the test dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Description\n",
    "-----------------\n",
    "Every observation in the dataset contains monthly behavior information about one user. The information given is as follows: \n",
    "\n",
    "—Åalls ‚Äî number of calls\n",
    "\n",
    "minutes ‚Äî total call duration in minutes\n",
    "\n",
    "messages ‚Äî number of text messages\n",
    "\n",
    "mb_used ‚Äî Internet traffic used in MB\n",
    "\n",
    "is_ultra ‚Äî plan for the current month (Ultra - 1, Smart - 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading packages and data\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/datasets/users_behavior.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking dataframe and datasets\n",
    "df.describe()\n",
    "df.info()\n",
    "df.isnull().sum()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there are no missing data values in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-left: 7px solid green; padding: 5px\">\n",
    "  <b>‚úÖ Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  Great start! All libraries were correctly imported, the dataset was loaded, and the initial inspection was done properly with no missing values detected.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\" style=\"border-left: 7px solid gold; padding: 5px\">\n",
    "  <b>‚ö†Ô∏è Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  Consider adding a few simple charts, like histograms or a correlation heatmap, to visualize data distributions and patterns more clearly.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Spliting\n",
    "--------------\n",
    "We are looking to split ths source datga into a training set, a validation set, and a test set. Since we are spliting the data into 3 sets, the validation set and test set should be equal.  I will split 20% for each and 60% for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1928, 4)\n",
      "(1928,)\n",
      "(643, 4)\n",
      "(643,)\n",
      "(643, 4)\n",
      "(643,)\n"
     ]
    }
   ],
   "source": [
    "features = df.drop(['is_ultra'], axis=1)\n",
    "target = df['is_ultra']\n",
    "features_train, features_temp, target_train, target_temp = train_test_split(\n",
    "    features, target, test_size=0.4, random_state=12345)\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(\n",
    "    features_temp, target_temp, test_size=0.5, random_state=12345)\n",
    "\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(target_valid.shape)\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-left: 7px solid green; padding: 5px\">\n",
    "  <b>‚úÖ Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  Nice work splitting the dataset into training, validation, and test sets with a balanced 60/20/20 ratio. The use of <code>random_state</code> ensures reproducibility, and the code structure is clear and correct.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Studying and Hyperparameters Tuning\n",
    "------------------------------------------\n",
    "Now that we have split our data into 60/20/20.  I will begin to apply different models to determine which will be the best according to the findings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree Model\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth = 1\n",
      "0.7542768273716952\n",
      "max_depth = 2\n",
      "0.7822706065318819\n",
      "max_depth = 3\n",
      "0.7853810264385692\n",
      "max_depth = 4\n",
      "0.7791601866251944\n",
      "max_depth = 5\n",
      "0.7791601866251944\n"
     ]
    }
   ],
   "source": [
    "for depth in range (1, 6):\n",
    "    model =  DecisionTreeClassifier(random_state = 12345, max_depth=depth)\n",
    "    model.fit(features_train, target_train)\n",
    "    predictions_valid = model.predict(features_valid)\n",
    "    print(\"max_depth =\", depth)\n",
    "    print(accuracy_score(target_valid, predictions_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that at the max depth of 3, we have the highest accuracy. As we increase the depth, we can see the accuracy began to temporary drop and if we continue, we will see the result of overfitting.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Model\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model on the validation set (n_estimators = 1): 0.7107309486780715\n",
      "Accuracy of model on the validation set (n_estimators = 2): 0.7636080870917574\n",
      "Accuracy of model on the validation set (n_estimators = 3): 0.7387247278382582\n",
      "Accuracy of model on the validation set (n_estimators = 4): 0.7713841368584758\n",
      "Accuracy of model on the validation set (n_estimators = 5): 0.749611197511664\n",
      "Accuracy of model on the validation set (n_estimators = 6): 0.7807153965785381\n",
      "Accuracy of model on the validation set (n_estimators = 7): 0.7682737169517885\n",
      "Accuracy of model on the validation set (n_estimators = 8): 0.7822706065318819\n",
      "Accuracy of model on the validation set (n_estimators = 9): 0.7729393468118196\n",
      "Accuracy of model on the validation set (n_estimators = 10): 0.7853810264385692\n",
      "Accuracy of model on the validation set (n_estimators = 11): 0.7838258164852255\n",
      "Accuracy of model on the validation set (n_estimators = 12): 0.7869362363919129\n",
      "Accuracy of model on the validation set (n_estimators = 13): 0.7822706065318819\n",
      "Accuracy of model on the validation set (n_estimators = 14): 0.7838258164852255\n",
      "Accuracy of model on the validation set (n_estimators = 15): 0.7838258164852255\n",
      "Accuracy of model on the validation set (n_estimators = 16): 0.7869362363919129\n",
      "Accuracy of model on the validation set (n_estimators = 17): 0.7869362363919129\n",
      "Accuracy of model on the validation set (n_estimators = 18): 0.7931570762052877\n",
      "Accuracy of model on the validation set (n_estimators = 19): 0.7884914463452566\n",
      "Accuracy of model on the validation set (n_estimators = 20): 0.7869362363919129\n",
      "Accuracy of model on the validation set (n_estimators = 21): 0.7931570762052877\n",
      "Accuracy of model on the validation set (n_estimators = 22): 0.7884914463452566\n",
      "Accuracy of model on the validation set (n_estimators = 23): 0.7947122861586314\n",
      "Accuracy of model on the validation set (n_estimators = 24): 0.7900466562986003\n",
      "Accuracy of model on the validation set (n_estimators = 25): 0.7838258164852255\n",
      "Accuracy of model on the validation set (n_estimators = 26): 0.7853810264385692\n",
      "Accuracy of model on the validation set (n_estimators = 27): 0.7853810264385692\n",
      "Accuracy of model on the validation set (n_estimators = 28): 0.7838258164852255\n",
      "Accuracy of model on the validation set (n_estimators = 29): 0.7791601866251944\n",
      "Accuracy of model on the validation set (n_estimators = 30): 0.7838258164852255\n",
      "Accuracy of model on the validation set (n_estimators = 31): 0.7822706065318819\n",
      "Accuracy of model on the validation set (n_estimators = 32): 0.7822706065318819\n",
      "Accuracy of model on the validation set (n_estimators = 33): 0.7807153965785381\n",
      "Accuracy of model on the validation set (n_estimators = 34): 0.7807153965785381\n",
      "Accuracy of model on the validation set (n_estimators = 35): 0.7776049766718507\n",
      "Accuracy of model on the validation set (n_estimators = 36): 0.7807153965785381\n",
      "Accuracy of model on the validation set (n_estimators = 37): 0.7776049766718507\n",
      "Accuracy of model on the validation set (n_estimators = 38): 0.7838258164852255\n",
      "Accuracy of model on the validation set (n_estimators = 39): 0.7807153965785381\n",
      "Accuracy of model on the validation set (n_estimators = 40): 0.7838258164852255\n",
      "Accuracy of model on the validation set (n_estimators = 41): 0.7869362363919129\n",
      "Accuracy of model on the validation set (n_estimators = 42): 0.7900466562986003\n",
      "Accuracy of model on the validation set (n_estimators = 43): 0.7853810264385692\n",
      "Accuracy of model on the validation set (n_estimators = 44): 0.7900466562986003\n",
      "Accuracy of model on the validation set (n_estimators = 45): 0.7884914463452566\n",
      "Accuracy of model on the validation set (n_estimators = 46): 0.7884914463452566\n",
      "Accuracy of model on the validation set (n_estimators = 47): 0.7869362363919129\n",
      "Accuracy of model on the validation set (n_estimators = 48): 0.7916018662519441\n",
      "Accuracy of model on the validation set (n_estimators = 49): 0.7884914463452566\n"
     ]
    }
   ],
   "source": [
    "for est in range(1, 50):\n",
    "    model = RandomForestClassifier(random_state=12345, n_estimators=est)\n",
    "    model.fit(features_train, target_train)\n",
    "    score = model.score(features_valid, target_valid)\n",
    "    print(\"Accuracy of model on the validation set (n_estimators = {}): {}\".format(est, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes about 10 estimators to get the a similar accuracy as our Decision Tree model.  The more estimators would mean more time needed for training.  As we continue to increase estimators, the accuracy does not continue to improve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logical Regression Model\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model = 0.7091757387247278\n"
     ]
    }
   ],
   "source": [
    "model =  LogisticRegression(random_state=12345, solver='liblinear')\n",
    "model.fit(features_train, target_train)\n",
    "predictions_valid = model.predict(features_valid)\n",
    "accuracy = model.score(features_valid, target_valid)\n",
    "print(\"Accuracy of model =\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logical Regression model has the lowest accuracy between all 3 models and is < 75% which is under our threshold that we want for this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-left: 7px solid green; padding: 5px\">\n",
    "  <b>‚úÖ Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  Excellent comparison of models and hyperparameters. You correctly explored multiple depths for Decision Tree, tested a range of estimators for Random Forest, and included Logistic Regression for reference. Your explanations about overfitting and accuracy trends show good understanding of model behavior.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Quality Check with Test Set\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final test accuracy: 0.7807153965785381\n",
      "Accuracy of the best model on the train set: 0.9937759336099585\n",
      "Accuracy of the best model on the validation set: 0.7947122861586314\n",
      "Accuracy of the best model on the test set: 0.7807153965785381\n"
     ]
    }
   ],
   "source": [
    "best_model = RandomForestClassifier(random_state=12345, n_estimators=23)\n",
    "best_model.fit(features_train, target_train)\n",
    "predictions_test = best_model.predict(features_test)\n",
    "final_accuracy = accuracy_score(target_test, predictions_test)\n",
    "print(\"Final test accuracy:\", final_accuracy)\n",
    "\n",
    "print('Accuracy of the best model on the train set:', best_model.score(features_train, target_train))\n",
    "print('Accuracy of the best model on the validation set:', best_model.score(features_valid, target_valid))\n",
    "print('Accuracy of the best model on the test set:', best_model.score(features_test, target_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score of best model = 0.5812807881773399\n",
      "Recall score of best model = 0.5812807881773399\n",
      "\n",
      "Detailed classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84       440\n",
      "           1       0.68      0.58      0.63       203\n",
      "\n",
      "    accuracy                           0.78       643\n",
      "   macro avg       0.75      0.73      0.74       643\n",
      "weighted avg       0.77      0.78      0.78       643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(best_model.predict(features_test), target_test)\n",
    "print('Precision score of best model =', precision)\n",
    "recall = recall_score(target_test, best_model.predict(features_test))\n",
    "print('Recall score of best model =', recall)\n",
    "print('\\nDetailed classification report:')\n",
    "print(classification_report(target_test, best_model.predict(features_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions and Sanity Check\n",
    "-\n",
    "Between the 3 models, Logistic Regression have the lowest accuracy and was not able to meet our threshold of 75%.\n",
    "Decision Tree model does not have an overfit problem at a max depth of 3.\n",
    "Random Forest model is indeed overfitted but yields the highest accuracy.\n",
    "\n",
    "Now just because we meet accuracy threshold for the project does not mean that the models are the best and completely applicable in real world predictions.  We noticed that the precision is quite low. With a precision of 58%, it means that 42% of customers that are recommended for Ultra either does not need it or is not utilizing it to its full capacity. This could lead to dissatisfication and frustration and could lose customers in the long term.  \n",
    "\n",
    "From a model perspective, our model might be a bit too aggressive in suggesting the Ultra plan to customers.  THe current Random Forest model will most likely require much adjustment in which I did not do because it did not say it was required in the project. We could control depth to limit the growth of each tree as well as potentially adding max_features to add more randomness and reduce overfitting.  \n",
    "\n",
    "If we are going with a more realistic approach, I would actually use Decision Tree model over Random Forest model because even though the accuracy is slightly lower with Decision Tree, it does not have an overfitting issue which would most likely lead to a higher precision score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\" style=\"border-left: 7px solid green; padding: 5px\">\n",
    "  <b>‚úÖ Reviewer‚Äôs comment ‚Äì Iteration 1:</b><br>\n",
    "  Excellent evaluation of the final model. You clearly tested on the unseen data, reported all key metrics (accuracy, precision, recall, and classification report), and provided a thoughtful interpretation of the results. The discussion on trade-offs between accuracy and overfitting demonstrates solid analytical thinking.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
